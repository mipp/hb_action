# Handball action recognition models

This repository contains code and trained model for handball action recognition in video clips. The code is based on [Kinetics-I3D](https://github.com/deepmind/kinetics-i3d) by Deepmind and additional code from [the GitHub repo](https://github.com/trevphil/TechniqueAnalysis/tree/master/video-classifier) by Trevor Philips.

The model was trained on [UNIRI-HDB](https://ieee-dataport.org/open-access/handball-action-dataset-uniri-hbd) dataset


## Prerequisites

You need to install:

- [Python](https://www.python.org/downloads/)
- [OpenCV](https://opencv.org/)
    1. `python -m pip install -U pip`
    1. `python -m pip install -U opencv-contrib-python`
- [Tensorflow](https://www.tensorflow.org/) 1.15
- [Sonnet](https://github.com/deepmind/sonnet) 1.36
    1. `python -m pip install -U dm-sonnet=1.36`


## Models
The model weights and example input and output can be downloaded here: [model weights](https://drive.google.com/file/d/1ry5_diz9xnHCHuZpv2dck9Z6JNOaosoS/view?usp=sharing).

## Usage 

To run the recognition on a video, the model requires the video file and the player tracks generated by e.g. [Deep SORT tracker](https://github.com/nwojke/deep_sort).
Running:
    
    python detektiraj_akcije.py --input tracks_file.txt --video video_file --output_dir directory_to_store_results

Where *video_file* is the video to run action recognition on, *tracks_file* is the file containing the player tracks output by the object tracker.

An example result video is in example_output.

## Acknowledgment
This research was fully supported by the Croatian Science Foundation under the project 
IP-2016-06-8345 “Automatic recognition of actions and activities in multimedia content from the sports domain” (RAASS) and by the University of Rijeka under the project number 18-222-1385

